{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Applications - Mini Project 2\n",
    "> By Oliver Dietsche & Simon Peier\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We decided to use part of the [Tiny ImageNet](https://www.kaggle.com/c/tiny-imagenet) dataset. \n",
    "\n",
    "According to the description in Kaggle, the Tiny ImageNet dataset has the following properties: \"Tiny ImageNet contains 200 classes for training. Each class has 500 images. The test set contains 10,000 images. All images are 64x64 colored ones.\" It fulfills all the required key characteristics, except that it has too many classes (and thus too many samples). To meet all criteria, we pre-processed the data-set and chose 6 classes to use. As the dataset contains lots of classes of different categories, we settled for classes from the animal realm.\n",
    "\n",
    "### Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"dataset\"\n",
    "words_file = os.path.join(data_dir, \"words.txt\")\n",
    "image_size = (64, 64)\n",
    "\n",
    "# Load words.txt\n",
    "with open(words_file, 'r') as f:\n",
    "    class_labels = {}\n",
    "    for line in f:\n",
    "        line = line.strip().split('\\t')\n",
    "        class_labels[line[0]] = line[1]\n",
    "\n",
    "# Load images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for folder_name in os.listdir(data_dir):\n",
    "    if folder_name.startswith('n'):\n",
    "        label = class_labels[folder_name]\n",
    "        image_folder_path = os.path.join(data_dir, folder_name, \"images\")\n",
    "        for image_name in os.listdir(image_folder_path):\n",
    "            image_path = os.path.join(image_folder_path, image_name)\n",
    "            image = img_to_array(load_img(image_path))\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into test and training data\n",
    "train_val_imgs, test_imgs, train_val_labels, test_labels = train_test_split(images, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and validation data\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_val_imgs, train_val_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
